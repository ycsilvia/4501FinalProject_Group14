{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "import math\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import keplergl\n",
    "from keplergl import KeplerGl\n",
    "import statistics\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between the two coordinates\n",
    "def calculate_distance(from_coord: list, to_coord: list) -> float:\n",
    "    R = 6373.0\n",
    "    lat1 = math.radians(from_coord[0])\n",
    "    lon1 = math.radians(from_coord[1])\n",
    "    lat2 = math.radians(to_coord[0])\n",
    "    lon2 = math.radians(to_coord[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the dataset that is not given the trip distance, calculate the distance using the given coordinate data and add it to the dataframe\n",
    "def add_distance_column(dataframe: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    distance = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        distance.append(calculate_distance((row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])))\n",
    "    dataframe['trip_distance'] = distance\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_parquet_urls() -> list:\n",
    "    response = requests.get(TAXI_URL)\n",
    "    soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = soup.find_all(lambda tag:'title' in tag.attrs and tag.attrs['title'] == \"Yellow Taxi Trip Records\")\n",
    "    hrefs = [link.get('href') for link in links]\n",
    "    # Filter the links based on the desired years (2009 to 2015)\n",
    "    hrefs_filtered = [href for href in hrefs \n",
    "                  if any(year in href for year in map(str, range(2009, 2015)))\n",
    "                  or (any(f\"2015-{month:02}\" in href for month in range(1, 7)))]\n",
    "    return hrefs_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_taxi_parquet_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that converts location to coordinates, and generate a dataframe\n",
    "def convert_id_to_coord(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    shapefile = gpd.read_file(r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\taxi_zones\\taxi_zones.shp\")\n",
    "    # Convert the geometry column in the shapefile into specific coordinates of latitude and longitude\n",
    "    shapefile = shapefile.to_crs(4326)\n",
    "    shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
    "    shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
    "    \n",
    "    df = df\n",
    "    df = df.loc[df[\"pulocationid\"] <= 263]\n",
    "    df = df.loc[df[\"pulocationid\"] != 0]\n",
    "    df = df.loc[df[\"dolocationid\"] <= 263]\n",
    "    df = df.loc[df[\"dolocationid\"] != 0]\n",
    "    # convert location IDs into longitude and latitude\n",
    "    PUlongitude = []\n",
    "    PUlatitude = []\n",
    "    DOlongitude = []\n",
    "    DOlatitude = []\n",
    "    # convert the pickup location IDs into longitude and latitude\n",
    "    for i in df['pulocationid']:\n",
    "        PUlatitude.append(shapefile['latitude'][i-1])\n",
    "        PUlongitude.append(shapefile['longitude'][i-1])\n",
    "    for i in df['dolocationid']:\n",
    "        DOlatitude.append(shapefile['latitude'][i-1])\n",
    "        DOlongitude.append(shapefile['longitude'][i-1])\n",
    "        \n",
    "    df['pickup_longitude'] = PUlongitude\n",
    "    df['pickup_latitude'] = PUlatitude\n",
    "    df['dropoff_longitude'] = DOlongitude\n",
    "    df['dropoff_latitude'] = DOlatitude\n",
    "    # convert the drop off location IDs into longitude and latitude\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain taxi data and clean the data\n",
    "def get_and_clean_month_taxi_data(url: str) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    df = pd.read_parquet(url)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df_taxi = pd.DataFrame()\n",
    "\n",
    "    # keep necessary columns into a new dataframe\n",
    "    if 'tpep_pickup_datetime' in df.columns:\n",
    "        df=df.rename(columns = {'tpep_pickup_datetime':'pickup_datetime',\n",
    "                                'tip_amount' : 'tip_amount'})\n",
    "        df=convert_id_to_coord(df)\n",
    "        \n",
    "    elif 'trip_pickup_datetime' in df.columns:\n",
    "        df=df.rename(columns = {'trip_pickup_datetime':'pickup_datetime', \n",
    "                                'start_lon': 'pickup_longitude',\n",
    "                                'start_lat': 'pickup_latitude',\n",
    "                                'end_lon': 'dropoff_longitude',\n",
    "                                'end_lat': 'dropoff_latitude',\n",
    "                                'tip_amt' : 'tip_amount'})\n",
    "        \n",
    "    df.drop(df.columns.difference(['pickup_datetime',\n",
    "                                    'trip_distance', \n",
    "                                    'pickup_latitude', \n",
    "                                    'pickup_longitude', \n",
    "                                    'dropoff_latitude', \n",
    "                                    'dropoff_longitude',\n",
    "                                   'tip_amount']), 1, inplace=True)\n",
    "    \n",
    "    df=df[df[\"pickup_longitude\"] <= -73.717047]  \n",
    "    df=df[df[\"pickup_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"pickup_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"pickup_latitude\"] <= 40.908524]\n",
    "    df=df[df[\"dropoff_longitude\"] <= -73.717047]\n",
    "    df=df[df[\"dropoff_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"dropoff_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"dropoff_latitude\"] <= 40.908524]\n",
    "\n",
    "    df = df.loc[df[\"pickup_datetime\"] != 0.0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "\n",
    "    all_taxi_dataframes = []\n",
    "\n",
    "    for parquet_url in parquet_urls:\n",
    "        dataframe = get_and_clean_month_taxi_data(parquet_url)\n",
    "        add_distance_column(dataframe)\n",
    "\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load uber data and clean the data\n",
    "def load_and_clean_uber_data(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    df = pd.read_csv(csv_file, on_bad_lines='skip')\n",
    "    df.columns = df.columns.str.lower()\n",
    "    add_distance_column(df)\n",
    "    df.drop(df.columns.difference(['pickup_datetime',\n",
    "                                     'trip_distance', \n",
    "                                     'pickup_latitude', \n",
    "                                     'pickup_longitude', \n",
    "                                     'dropoff_latitude', \n",
    "                                     'dropoff_longitude']), 1, inplace=True)\n",
    "\n",
    "    # remove rows start and/or end outside of the following latitude/longitude coordinate box: \n",
    "    # (40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    df=df[df[\"pickup_longitude\"] <= -73.717047]  \n",
    "    df=df[df[\"pickup_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"pickup_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"pickup_latitude\"] <= 40.908524]\n",
    "    df=df[df[\"dropoff_longitude\"] <= -73.717047]\n",
    "    df=df[df[\"dropoff_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"dropoff_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"dropoff_latitude\"] <= 40.908524]\n",
    "\n",
    "    # remove invalid rows thtat pickup time is 0\n",
    "    df = df.loc[df[\"pickup_datetime\"] != 0.0]\n",
    "\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\1263730049.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.037958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.662205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.476855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.112245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.875639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.854353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.540827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.419484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  trip_distance  \n",
       "0              -73.999512         40.723217       1.683851  \n",
       "1              -73.994710         40.750325       2.458361  \n",
       "2              -73.962565         40.772647       5.037958  \n",
       "3              -73.965316         40.803349       1.662205  \n",
       "4              -73.973082         40.761247       4.476855  \n",
       "...                   ...               ...            ...  \n",
       "199995         -73.986525         40.740297       0.112245  \n",
       "199996         -74.006672         40.739620       1.875639  \n",
       "199997         -73.858957         40.692588      12.854353  \n",
       "199998         -73.983215         40.695415       3.540827  \n",
       "199999         -73.985508         40.768793       5.419484  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_uber_data(UBER_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    # read file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #drop unnecessary colums\n",
    "    df.drop(df.columns.difference(['DATE',\n",
    "                                   'HourlyPrecipitation', \n",
    "                                   'HourlyWindSpeed']), 1, inplace=True)\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace('T', 0.0)\n",
    "    # drop na values\n",
    "    df.dropna(subset=['HourlyWindSpeed'], inplace=True)\n",
    "    # convert \"DATE\" to datetime type\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    # convert \"HourlyPrecipitation\" to float type\n",
    "    df['HourlyPrecipitation'] = pd.to_numeric(df['HourlyPrecipitation'], errors='coerce')\n",
    "    # fill in missing values\n",
    "    df['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    # cast \"df\" to specified type\n",
    "    df = df.astype({'HourlyWindSpeed': 'float32', 'HourlyPrecipitation': 'float32'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    # read file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Replace data of the string type\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace('T', 0.0)\n",
    "    # convert \"DATE\" to datetime type\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    # convert \"HourlyPrecipitation\" to numeric type\n",
    "    df['HourlyPrecipitation'] = pd.to_numeric(df['HourlyPrecipitation'], errors='coerce')\n",
    "    # convert value of 'na' into 0.0\n",
    "    df['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    #drop unnecessary colums\n",
    "    df.drop(df.columns.difference(['DATE',\n",
    "                                   'HourlyPrecipitation', \n",
    "                                   'HourlyWindSpeed']), 1, inplace=True)\n",
    "    # calculate hourly average as a daily values\n",
    "    df['DATE'] = df['DATE'].dt.date\n",
    "    df = df.groupby('DATE', as_index=False).agg({'HourlyWindSpeed': np.mean, 'HourlyPrecipitation': np.mean})\n",
    "    df['HourlyWindSpeed'] = df['HourlyWindSpeed'].map(lambda x: round(x, 2))\n",
    "    # remame columns\n",
    "    df.rename(columns={'HourlyWindSpeed': 'DailyAverageWindSpeed', 'HourlyPrecipitation': 'DailyPrecipitation'}, inplace=True)\n",
    "    df = df.astype({'DailyAverageWindSpeed':'float32', 'DailyPrecipitation':'float32', 'DATE' : 'datetime64[ns]'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data() -> pd.core.frame.DataFrame:\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2009_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2010_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2011_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2012_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2013_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2014_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2015_weather.csv\"\n",
    "        ]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n"
     ]
    }
   ],
   "source": [
    "hourly_data, daily_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>2015-12-31 18:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>2015-12-31 19:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>2015-12-31 22:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>2015-12-31 23:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73713 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009-01-01 00:51:00                  0.0             18.0\n",
       "1     2009-01-01 01:51:00                  0.0             18.0\n",
       "2     2009-01-01 02:51:00                  0.0             18.0\n",
       "3     2009-01-01 03:51:00                  0.0              8.0\n",
       "4     2009-01-01 04:51:00                  0.0             11.0\n",
       "...                   ...                  ...              ...\n",
       "11379 2015-12-31 18:51:00                  0.0              3.0\n",
       "11380 2015-12-31 19:51:00                  0.0              6.0\n",
       "11381 2015-12-31 20:51:00                  0.0             10.0\n",
       "11383 2015-12-31 22:51:00                  0.0              7.0\n",
       "11384 2015-12-31 23:51:00                  0.0              5.0\n",
       "\n",
       "[73713 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>6.93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.003542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.019375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.007436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  DailyAverageWindSpeed  DailyPrecipitation\n",
       "0   2009-01-01                  11.04            0.000000\n",
       "1   2009-01-02                   6.81            0.000000\n",
       "2   2009-01-03                   9.88            0.000000\n",
       "3   2009-01-04                   7.37            0.000000\n",
       "4   2009-01-05                   6.93            0.000000\n",
       "..         ...                    ...                 ...\n",
       "360 2015-12-27                   4.91            0.003542\n",
       "361 2015-12-28                   8.21            0.001154\n",
       "362 2015-12-29                   7.79            0.019375\n",
       "363 2015-12-30                   4.18            0.007436\n",
       "364 2015-12-31                   4.74            0.002286\n",
       "\n",
       "[2551 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sunset_sunrise_daily(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df = df.astype({'Sunrise': 'int32', 'Sunset': 'int32', 'DATE':'datetime64[ns]' })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_sunrise_sunset_data() -> pd.core.frame.DataFrame:\n",
    "    sunrise_sunset_dataframes =[]\n",
    "    \n",
    "    weather_csv_files = [\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2009_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2010_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2011_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2012_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2013_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2014_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2015_weather.csv\"\n",
    "        ]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        sunrise_sunset_dataframe = clean_sunset_sunrise_daily(csv_file)\n",
    "        sunrise_sunset_dataframes.append(sunrise_sunset_dataframe)\n",
    "        \n",
    "    sunrise_sunset_data = pd.concat(sunrise_sunset_dataframes)\n",
    "    sunrise_sunset_data['DATE'] = pd.to_datetime(sunrise_sunset_data['DATE'])\n",
    "    sunrise_sunset_data = sunrise_sunset_data.astype({'Sunrise': 'int32', 'Sunset': 'int32'})\n",
    "    \n",
    "    return sunrise_sunset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2009-01-02 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2009-01-06 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2009-01-07 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2009-01-10 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2009-01-11 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>2015-12-27 23:59:00</td>\n",
       "      <td>719</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>2015-12-28 23:59:00</td>\n",
       "      <td>719</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>2015-12-29 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>2015-12-30 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>2015-12-31 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  Sunrise  Sunset\n",
       "55    2009-01-02 23:59:00      720    1640\n",
       "163   2009-01-06 23:59:00      720    1644\n",
       "202   2009-01-07 23:59:00      720    1645\n",
       "305   2009-01-10 23:59:00      720    1648\n",
       "343   2009-01-11 23:59:00      720    1649\n",
       "...                   ...      ...     ...\n",
       "11238 2015-12-27 23:59:00      719    1635\n",
       "11264 2015-12-28 23:59:00      719    1636\n",
       "11312 2015-12-29 23:59:00      720    1636\n",
       "11351 2015-12-30 23:59:00      720    1637\n",
       "11385 2015-12-31 23:59:00      720    1638\n",
       "\n",
       "[1826 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunrise_sunset_data = load_and_clean_sunrise_sunset_data()\n",
    "sunrise_sunset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\1263730049.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "uber_data = load_and_clean_uber_data(UBER_CSV)\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "sunrise_sunset_data = load_and_clean_sunrise_sunset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parquet_urls = find_taxi_parquet_urls()\n",
    "all_parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "taxi_data = pd.read_csv(r'C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\taxi_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-10 13:23:16</td>\n",
       "      <td>2.000</td>\n",
       "      <td>-73.982541</td>\n",
       "      <td>40.763843</td>\n",
       "      <td>-73.987940</td>\n",
       "      <td>40.741227</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-14 17:39:16</td>\n",
       "      <td>1.300</td>\n",
       "      <td>-73.995395</td>\n",
       "      <td>40.749472</td>\n",
       "      <td>-74.004407</td>\n",
       "      <td>40.742506</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-26 06:21:00</td>\n",
       "      <td>19.260</td>\n",
       "      <td>-73.776892</td>\n",
       "      <td>40.645983</td>\n",
       "      <td>-73.982210</td>\n",
       "      <td>40.772557</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-07 07:56:59</td>\n",
       "      <td>15.400</td>\n",
       "      <td>-73.863361</td>\n",
       "      <td>40.769973</td>\n",
       "      <td>-74.008209</td>\n",
       "      <td>40.703672</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-15 17:54:00</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-73.985552</td>\n",
       "      <td>40.747653</td>\n",
       "      <td>-73.966978</td>\n",
       "      <td>40.768760</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195467</th>\n",
       "      <td>18191</td>\n",
       "      <td>2015-06-01 12:25:22</td>\n",
       "      <td>2.880</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195468</th>\n",
       "      <td>18192</td>\n",
       "      <td>2015-06-07 23:02:31</td>\n",
       "      <td>12.100</td>\n",
       "      <td>-73.786533</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.917711</td>\n",
       "      <td>40.700522</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195469</th>\n",
       "      <td>18193</td>\n",
       "      <td>2015-06-18 07:41:01</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195470</th>\n",
       "      <td>18194</td>\n",
       "      <td>2015-06-09 12:59:25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.970443</td>\n",
       "      <td>40.749914</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195471</th>\n",
       "      <td>18195</td>\n",
       "      <td>2015-06-13 04:10:05</td>\n",
       "      <td>4.800</td>\n",
       "      <td>-73.996919</td>\n",
       "      <td>40.720889</td>\n",
       "      <td>-73.939287</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      pickup_datetime  trip_distance  pickup_longitude  \\\n",
       "0                0  2009-01-10 13:23:16          2.000        -73.982541   \n",
       "1                1  2009-01-14 17:39:16          1.300        -73.995395   \n",
       "2                2  2009-01-26 06:21:00         19.260        -73.776892   \n",
       "3                3  2009-01-07 07:56:59         15.400        -73.863361   \n",
       "4                4  2009-01-15 17:54:00          0.171        -73.985552   \n",
       "...            ...                  ...            ...               ...   \n",
       "195467       18191  2015-06-01 12:25:22          2.880        -73.977698   \n",
       "195468       18192  2015-06-07 23:02:31         12.100        -73.786533   \n",
       "195469       18193  2015-06-18 07:41:01          0.840        -73.984196   \n",
       "195470       18194  2015-06-09 12:59:25          0.500        -73.977698   \n",
       "195471       18195  2015-06-13 04:10:05          4.800        -73.996919   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  tip_amount  \n",
       "0             40.763843         -73.987940         40.741227        1.92  \n",
       "1             40.749472         -74.004407         40.742506        3.00  \n",
       "2             40.645983         -73.982210         40.772557        0.00  \n",
       "3             40.769973         -74.008209         40.703672        0.00  \n",
       "4             40.747653         -73.966978         40.768760        0.00  \n",
       "...                 ...                ...               ...         ...  \n",
       "195467        40.758028         -74.008984         40.735035        0.00  \n",
       "195468        40.646985         -73.917711         40.700522        7.46  \n",
       "195469        40.759818         -73.977698         40.758028        0.00  \n",
       "195470        40.758028         -73.970443         40.749914        1.95  \n",
       "195471        40.720889         -73.939287         40.674469        2.00  \n",
       "\n",
       "[195472 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Date, Integer, Float, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_8720\\2793077822.py:1: SAWarning: This declarative base already contains a class with the same class name and module name as __main__.HourlyWeather, and will be replaced in the string-lookup table.\n",
      "  class HourlyWeather(Base):\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Table 'hourly_weathers' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHourlyWeather\u001b[39;00m(Base):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     __tablename__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhourly_weathers\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m Column(Integer, primary_key\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\orm\\decl_api.py:76\u001b[0m, in \u001b[0;36mDeclarativeMeta.__init__\u001b[1;34m(cls, classname, bases, dict_, **kw)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_sa_registry \u001b[39m=\u001b[39m reg\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m__abstract__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 76\u001b[0m     _as_declarative(reg, \u001b[39mcls\u001b[39;49m, dict_)\n\u001b[0;32m     77\u001b[0m \u001b[39mtype\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mcls\u001b[39m, classname, bases, dict_)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\orm\\decl_base.py:126\u001b[0m, in \u001b[0;36m_as_declarative\u001b[1;34m(registry, cls, dict_)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_as_declarative\u001b[39m(registry, \u001b[39mcls\u001b[39m, dict_):\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m     \u001b[39m# declarative scans the class for attributes.  no table or mapper\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[39m# args passed separately.\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m _MapperConfig\u001b[39m.\u001b[39;49msetup_mapping(registry, \u001b[39mcls\u001b[39;49m, dict_, \u001b[39mNone\u001b[39;49;00m, {})\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\orm\\decl_base.py:183\u001b[0m, in \u001b[0;36m_MapperConfig.setup_mapping\u001b[1;34m(cls, registry, cls_, dict_, table, mapper_kw)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     cfg_cls \u001b[39m=\u001b[39m _ClassScanMapperConfig\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m cfg_cls(registry, cls_, dict_, table, mapper_kw)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\orm\\decl_base.py:331\u001b[0m, in \u001b[0;36m_ClassScanMapperConfig.__init__\u001b[1;34m(self, registry, cls_, dict_, table, mapper_kw)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_mappable_attributes()\n\u001b[0;32m    329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_declared_columns()\n\u001b[1;32m--> 331\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_table(table)\n\u001b[0;32m    333\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_inheritance(mapper_kw)\n\u001b[0;32m    335\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_mapping(mapper_kw)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\orm\\decl_base.py:820\u001b[0m, in \u001b[0;36m_ClassScanMapperConfig._setup_table\u001b[1;34m(self, table)\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m autoload:\n\u001b[0;32m    816\u001b[0m             table_kw[\u001b[39m\"\u001b[39m\u001b[39mautoload\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    818\u001b[0m         table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cls_attribute(\n\u001b[0;32m    819\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m__table__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m--> 820\u001b[0m             table_cls(\n\u001b[0;32m    821\u001b[0m                 tablename,\n\u001b[0;32m    822\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata_for_cls(manager),\n\u001b[0;32m    823\u001b[0m                 \u001b[39m*\u001b[39m(\u001b[39mtuple\u001b[39m(declared_columns) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(args)),\n\u001b[0;32m    824\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtable_kw\n\u001b[0;32m    825\u001b[0m             ),\n\u001b[0;32m    826\u001b[0m         )\n\u001b[0;32m    827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m table \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kw)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    303\u001b[0m         _warn_with_version(\n\u001b[0;32m    304\u001b[0m             messages[m],\n\u001b[0;32m    305\u001b[0m             versions[m],\n\u001b[0;32m    306\u001b[0m             version_warnings[m],\n\u001b[0;32m    307\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m    308\u001b[0m         )\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\schema.py:593\u001b[0m, in \u001b[0;36mTable.__new__\u001b[1;34m(cls, *args, **kw)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m metadata\u001b[39m.\u001b[39mtables:\n\u001b[0;32m    592\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m keep_existing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m extend_existing \u001b[39mand\u001b[39;00m \u001b[39mbool\u001b[39m(args):\n\u001b[1;32m--> 593\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mInvalidRequestError(\n\u001b[0;32m    594\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is already defined for this MetaData \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minstance.  Specify \u001b[39m\u001b[39m'\u001b[39m\u001b[39mextend_existing=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mto redefine \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moptions and columns on an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    598\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mexisting Table object.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key\n\u001b[0;32m    599\u001b[0m         )\n\u001b[0;32m    600\u001b[0m     table \u001b[39m=\u001b[39m metadata\u001b[39m.\u001b[39mtables[key]\n\u001b[0;32m    601\u001b[0m     \u001b[39mif\u001b[39;00m extend_existing:\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Table 'hourly_weathers' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object."
     ]
    }
   ],
   "source": [
    "class HourlyWeather(Base):\n",
    "    __tablename__ = 'hourly_weathers'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    Date = Column(Date)\n",
    "    HourlyPrecipitation = Column(Float)\n",
    "    HourlyWindSpeed = Column(Float)\n",
    "\n",
    "class DailyWeather(Base):\n",
    "    __tablename__ = 'daily_weathers'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    Date = Column(Date)\n",
    "    DailyPrecipitation = Column(Float)\n",
    "    DailyAverageWindSpeed = Column(Float)\n",
    "\n",
    "class TaxiTrip(Base):\n",
    "    __tablename__ = 'taxi_trips'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pickup_datetime = Column(Date)\n",
    "    trip_distance = Column(Float)\n",
    "    pickup_longitude = Column(Float)\n",
    "    pickup_latitude = Column(Float)\n",
    "    dropoff_longitude = Column(Float)\n",
    "    dropoff_latitude = Column(Float)\n",
    "\n",
    "class UberTrip(Base):\n",
    "    __tablename__ = 'uber_trips'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    pickup_datetime = Column(Date)\n",
    "    trip_distance = Column(Float)\n",
    "    pickup_longitude = Column(Float)\n",
    "    pickup_latitude = Column(Float)\n",
    "    dropoff_longitude = Column(Float)\n",
    "    dropoff_latitude = Column(Float)\n",
    "\n",
    "class Sunrise_Sunset(Base):\n",
    "    __tablename__ = 'sunrise_sunsets'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    Date = Column(Date)\n",
    "    Sunrise = Column(Integer)\n",
    "    Sunset = Column(Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    weatherId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Date DATE,\n",
    "    HourlyPrecipitation FLOAT,\n",
    "    HourlyWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    weatherId INTEGER PRIMARY KEY AUTOINCREMENT\n",
    "    Date DATE,\n",
    "    DailyPrecipitation FLOAT,\n",
    "    DailyAverageWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    taxi_tripId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_datetime DATE,\n",
    "    distance FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    uber_tripId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_datetime DATE,\n",
    "    distance FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "SUNRISE_SUNSET_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sunrise_sunsets\n",
    "(\n",
    "    sunrise_sunsetID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Date DATE,\n",
    "    Sunrise INTEGER,\n",
    "    Sunset INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(\"project.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'uber_trips' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m uber_data\u001b[39m.\u001b[39;49mto_sql(\u001b[39m\"\u001b[39;49m\u001b[39muber_trips\u001b[39;49m\u001b[39m\"\u001b[39;49m, con \u001b[39m=\u001b[39;49m connection,schema\u001b[39m=\u001b[39;49mUBER_TRIPS_SCHEMA)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m taxi_data\u001b[39m.\u001b[39mto_sql(\u001b[39m\"\u001b[39m\u001b[39mtaxi_trips\u001b[39m\u001b[39m\"\u001b[39m, con \u001b[39m=\u001b[39m connection,schema\u001b[39m=\u001b[39mTAXI_TRIPS_SCHEMA)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m daily_weather_data\u001b[39m.\u001b[39mto_sql(\u001b[39m\"\u001b[39m\u001b[39mdaily_weathers\u001b[39m\u001b[39m\"\u001b[39m, con \u001b[39m=\u001b[39m connection,schema\u001b[39m=\u001b[39mDAILY_WEATHER_SCHEMA)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2987\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2988\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2989\u001b[0m     name,\n\u001b[0;32m   2990\u001b[0m     con,\n\u001b[0;32m   2991\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2992\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2993\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2994\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2995\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2996\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2997\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2998\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    692\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    693\u001b[0m     )\n\u001b[1;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mto_sql(\n\u001b[0;32m    696\u001b[0m     frame,\n\u001b[0;32m    697\u001b[0m     name,\n\u001b[0;32m    698\u001b[0m     if_exists\u001b[39m=\u001b[39mif_exists,\n\u001b[0;32m    699\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m    700\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m    701\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[0;32m    702\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m    703\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    704\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m    706\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:2187\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, **kwargs)\u001b[0m\n\u001b[0;32m   2176\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mmy_type\u001b[39m}\u001b[39;00m\u001b[39m) not a string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2178\u001b[0m table \u001b[39m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2179\u001b[0m     name,\n\u001b[0;32m   2180\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2185\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   2186\u001b[0m )\n\u001b[1;32m-> 2187\u001b[0m table\u001b[39m.\u001b[39;49mcreate()\n\u001b[0;32m   2188\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:829\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 829\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    830\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    831\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpd_sql\u001b[39m.\u001b[39mdrop_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'uber_trips' already exists."
     ]
    }
   ],
   "source": [
    "uber_data.to_sql(\"uber_trips\", con = connection,schema=UBER_TRIPS_SCHEMA)\n",
    "taxi_data.to_sql(\"taxi_trips\", con = connection,schema=TAXI_TRIPS_SCHEMA)\n",
    "daily_weather_data.to_sql(\"daily_weathers\", con = connection,schema=DAILY_WEATHER_SCHEMA)\n",
    "hourly_weather_data.to_sql(\"hourly_weathers\", con = connection,schema=HOURLY_WEATHER_SCHEMA)\n",
    "sunrise_sunset_data.to_sql(\"sunrise_sunsets\", con = connection, schema=SUNRISE_SUNSET_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "SELECT strftime ('%H',pickup_datetime) AS HOUR,\n",
    "COUNT(strftime ('%H',pickup_datetime)) AS Trip_counts\n",
    "FROM taxi_trips\n",
    "GROUP BY HOUR\n",
    "ORDER BY Trip_counts DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00', 49)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
