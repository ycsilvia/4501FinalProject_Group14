{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "import math\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import keplergl\n",
    "from keplergl import KeplerGl\n",
    "import statistics\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between the two coordinates\n",
    "def calculate_distance(from_coord: list, to_coord: list) -> float:\n",
    "    R = 6373.0\n",
    "    lat1 = math.radians(from_coord[0])\n",
    "    lon1 = math.radians(from_coord[1])\n",
    "    lat2 = math.radians(to_coord[0])\n",
    "    lon2 = math.radians(to_coord[1])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the dataset that is not given the trip distance, calculate the distance using the given coordinate data and add it to the dataframe\n",
    "def add_distance_column(dataframe: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    distance = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        distance.append(calculate_distance((row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])))\n",
    "    dataframe['trip_distance'] = distance\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_parquet_urls() -> list:\n",
    "    response = requests.get(TAXI_URL)\n",
    "    soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = soup.find_all(lambda tag:'title' in tag.attrs and tag.attrs['title'] == \"Yellow Taxi Trip Records\")\n",
    "    hrefs = [link.get('href') for link in links]\n",
    "    # Filter the links based on the desired years (2009 to 2015)\n",
    "    hrefs_filtered = [href for href in hrefs \n",
    "                  if any(year in href for year in map(str, range(2009, 2015)))\n",
    "                  or (any(f\"2015-{month:02}\" in href for month in range(1, 7)))]\n",
    "    return hrefs_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_taxi_parquet_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that converts location to coordinates, and generate a dataframe\n",
    "def convert_id_to_coord(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    shapefile = gpd.read_file(r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\taxi_zones\\taxi_zones.shp\")\n",
    "    # Convert the geometry column in the shapefile into specific coordinates of latitude and longitude\n",
    "    shapefile = shapefile.to_crs(4326)\n",
    "    shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
    "    shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
    "    \n",
    "    df = df\n",
    "    df = df.loc[df[\"pulocationid\"] <= 263]\n",
    "    df = df.loc[df[\"pulocationid\"] != 0]\n",
    "    df = df.loc[df[\"dolocationid\"] <= 263]\n",
    "    df = df.loc[df[\"dolocationid\"] != 0]\n",
    "    # convert location IDs into longitude and latitude\n",
    "    PUlongitude = []\n",
    "    PUlatitude = []\n",
    "    DOlongitude = []\n",
    "    DOlatitude = []\n",
    "    # convert the pickup location IDs into longitude and latitude\n",
    "    for i in df['pulocationid']:\n",
    "        PUlatitude.append(shapefile['latitude'][i-1])\n",
    "        PUlongitude.append(shapefile['longitude'][i-1])\n",
    "    for i in df['dolocationid']:\n",
    "        DOlatitude.append(shapefile['latitude'][i-1])\n",
    "        DOlongitude.append(shapefile['longitude'][i-1])\n",
    "        \n",
    "    df['pickup_longitude'] = PUlongitude\n",
    "    df['pickup_latitude'] = PUlatitude\n",
    "    df['dropoff_longitude'] = DOlongitude\n",
    "    df['dropoff_latitude'] = DOlatitude\n",
    "    # convert the drop off location IDs into longitude and latitude\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:11:33</td>\n",
       "      <td>2015-01-01 00:16:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>41</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:18:24</td>\n",
       "      <td>2015-01-01 00:24:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>166</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:26:19</td>\n",
       "      <td>2015-01-01 00:41:06</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.40</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:45:26</td>\n",
       "      <td>2015-01-01 00:53:20</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.87</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:59:21</td>\n",
       "      <td>2015-01-01 01:05:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741030</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31 23:21:42</td>\n",
       "      <td>2015-01-31 23:31:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.62</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741031</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31 23:42:43</td>\n",
       "      <td>2015-01-31 23:49:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741032</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31 23:55:16</td>\n",
       "      <td>2015-02-01 00:16:45</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741033</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31 23:20:53</td>\n",
       "      <td>2015-02-01 00:07:35</td>\n",
       "      <td>1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>189</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12741034</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31 23:40:15</td>\n",
       "      <td>2015-01-31 23:56:52</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.55</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12741035 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0                1  2015-01-01 00:11:33   2015-01-01 00:16:48   \n",
       "1                1  2015-01-01 00:18:24   2015-01-01 00:24:20   \n",
       "2                1  2015-01-01 00:26:19   2015-01-01 00:41:06   \n",
       "3                1  2015-01-01 00:45:26   2015-01-01 00:53:20   \n",
       "4                1  2015-01-01 00:59:21   2015-01-01 01:05:24   \n",
       "...            ...                  ...                   ...   \n",
       "12741030         1  2015-01-31 23:21:42   2015-01-31 23:31:00   \n",
       "12741031         1  2015-01-31 23:42:43   2015-01-31 23:49:32   \n",
       "12741032         1  2015-01-31 23:55:16   2015-02-01 00:16:45   \n",
       "12741033         1  2015-01-31 23:20:53   2015-02-01 00:07:35   \n",
       "12741034         1  2015-01-31 23:40:15   2015-01-31 23:56:52   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                       1            1.0           1                  N   \n",
       "1                       1            0.9           1                  N   \n",
       "2                       1            3.5           1                  N   \n",
       "3                       1            2.1           1                  N   \n",
       "4                       1            1.0           1                  N   \n",
       "...                   ...            ...         ...                ...   \n",
       "12741030                1            1.6           1                  N   \n",
       "12741031                1            0.6           1                  N   \n",
       "12741032                1            3.0           1                  N   \n",
       "12741033                1            6.9           1                  N   \n",
       "12741034                1            3.6           1                  N   \n",
       "\n",
       "          PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
       "0                   41           166             1          5.7    0.5   \n",
       "1                  166           238             3          6.0    0.5   \n",
       "2                  238           162             1         13.2    0.5   \n",
       "3                  162           263             1          8.2    0.5   \n",
       "4                  236           141             3          6.0    0.5   \n",
       "...                ...           ...           ...          ...    ...   \n",
       "12741030            90           249             1          8.0    0.5   \n",
       "12741031            90            68             1          6.0    0.5   \n",
       "12741032            68           148             1         15.0    0.5   \n",
       "12741033           189           237             1         32.5    0.5   \n",
       "12741034           162           145             1         15.0    0.5   \n",
       "\n",
       "          mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0             0.5        1.40           0.0                    0.0   \n",
       "1             0.5        0.00           0.0                    0.0   \n",
       "2             0.5        2.90           0.0                    0.0   \n",
       "3             0.5        2.37           0.0                    0.0   \n",
       "4             0.5        0.00           0.0                    0.0   \n",
       "...           ...         ...           ...                    ...   \n",
       "12741030      0.5        2.32           0.0                    0.3   \n",
       "12741031      0.5        1.46           0.0                    0.3   \n",
       "12741032      0.5        4.07           0.0                    0.3   \n",
       "12741033      0.5        6.00           0.0                    0.3   \n",
       "12741034      0.5        3.25           0.0                    0.3   \n",
       "\n",
       "          total_amount congestion_surcharge airport_fee  \n",
       "0                 8.40                 None        None  \n",
       "1                 7.30                 None        None  \n",
       "2                17.40                 None        None  \n",
       "3                11.87                 None        None  \n",
       "4                 7.30                 None        None  \n",
       "...                ...                  ...         ...  \n",
       "12741030         11.62                 None        None  \n",
       "12741031          8.76                 None        None  \n",
       "12741032         20.37                 None        None  \n",
       "12741033         39.80                 None        None  \n",
       "12741034         19.55                 None        None  \n",
       "\n",
       "[12741035 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain taxi data and clean the data\n",
    "def get_and_clean_month_taxi_data(url: str) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    df = pd.read_parquet(url)\n",
    "    df = df[:10]\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df_taxi = pd.DataFrame()\n",
    "\n",
    "    # keep necessary columns into a new dataframe\n",
    "    if 'tpep_pickup_datetime' in df.columns:\n",
    "        df=df.rename(columns = {'tpep_pickup_datetime':'pickup_datetime',\n",
    "                                'tip_amount' : 'tip_amount'})\n",
    "        df=convert_id_to_coord(df)\n",
    "        \n",
    "    elif 'trip_pickup_datetime' in df.columns:\n",
    "        df=df.rename(columns = {'trip_pickup_datetime':'pickup_datetime', \n",
    "                                'start_lon': 'pickup_longitude',\n",
    "                                'start_lat': 'pickup_latitude',\n",
    "                                'end_lon': 'dropoff_longitude',\n",
    "                                'end_lat': 'dropoff_latitude',\n",
    "                                'tip_amt' : 'tip_amount'})\n",
    "        \n",
    "    df.drop(df.columns.difference(['pickup_datetime',\n",
    "                                    'trip_distance', \n",
    "                                    'pickup_latitude', \n",
    "                                    'pickup_longitude', \n",
    "                                    'dropoff_latitude', \n",
    "                                    'dropoff_longitude',\n",
    "                                   'tip_amount']), 1, inplace=True)\n",
    "    \n",
    "    df=df[df[\"pickup_longitude\"] <= -73.717047]  \n",
    "    df=df[df[\"pickup_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"pickup_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"pickup_latitude\"] <= 40.908524]\n",
    "    df=df[df[\"dropoff_longitude\"] <= -73.717047]\n",
    "    df=df[df[\"dropoff_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"dropoff_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"dropoff_latitude\"] <= 40.908524]\n",
    "\n",
    "    df = df.loc[df[\"pickup_datetime\"] != 0.0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2223629645.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n"
     ]
    }
   ],
   "source": [
    "df = get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "\n",
    "    all_taxi_dataframes = []\n",
    "\n",
    "    for parquet_url in parquet_urls:\n",
    "        dataframe = get_and_clean_month_taxi_data(parquet_url)\n",
    "        add_distance_column(dataframe)\n",
    "\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load uber data and clean the data\n",
    "def load_and_clean_uber_data(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    df = pd.read_csv(csv_file, on_bad_lines='skip')\n",
    "    df.columns = df.columns.str.lower()\n",
    "    add_distance_column(df)\n",
    "    df.drop(df.columns.difference(['pickup_datetime',\n",
    "                                     'trip_distance', \n",
    "                                     'pickup_latitude', \n",
    "                                     'pickup_longitude', \n",
    "                                     'dropoff_latitude', \n",
    "                                     'dropoff_longitude']), 1, inplace=True)\n",
    "\n",
    "    # remove rows start and/or end outside of the following latitude/longitude coordinate box: \n",
    "    # (40.560445, -74.242330) and (40.908524, -73.717047)\n",
    "    df=df[df[\"pickup_longitude\"] <= -73.717047]  \n",
    "    df=df[df[\"pickup_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"pickup_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"pickup_latitude\"] <= 40.908524]\n",
    "    df=df[df[\"dropoff_longitude\"] <= -73.717047]\n",
    "    df=df[df[\"dropoff_longitude\"] >= -74.242330]\n",
    "    df=df[df[\"dropoff_latitude\"] >= 40.560445]\n",
    "    df=df[df[\"dropoff_latitude\"] <= 40.908524]\n",
    "\n",
    "    # remove invalid rows thtat pickup time is 0\n",
    "    df = df.loc[df[\"pickup_datetime\"] != 0.0]\n",
    "\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\1263730049.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.037958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.662205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.476855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.112245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.875639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.854353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.540827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.419484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  trip_distance  \n",
       "0              -73.999512         40.723217       1.683851  \n",
       "1              -73.994710         40.750325       2.458361  \n",
       "2              -73.962565         40.772647       5.037958  \n",
       "3              -73.965316         40.803349       1.662205  \n",
       "4              -73.973082         40.761247       4.476855  \n",
       "...                   ...               ...            ...  \n",
       "199995         -73.986525         40.740297       0.112245  \n",
       "199996         -74.006672         40.739620       1.875639  \n",
       "199997         -73.858957         40.692588      12.854353  \n",
       "199998         -73.983215         40.695415       3.540827  \n",
       "199999         -73.985508         40.768793       5.419484  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_uber_data(UBER_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    # read file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #drop unnecessary colums\n",
    "    df.drop(df.columns.difference(['DATE',\n",
    "                                   'HourlyPrecipitation', \n",
    "                                   'HourlyWindSpeed']), 1, inplace=True)\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace('T', 0.0)\n",
    "    # drop na values\n",
    "    df.dropna(subset=['HourlyWindSpeed'], inplace=True)\n",
    "    # convert \"DATE\" to datetime type\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    # convert \"HourlyPrecipitation\" to float type\n",
    "    df['HourlyPrecipitation'] = pd.to_numeric(df['HourlyPrecipitation'], errors='coerce')\n",
    "    # fill in missing values\n",
    "    df['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    # cast \"df\" to specified type\n",
    "    df = df.astype({'HourlyWindSpeed': 'float32', 'HourlyPrecipitation': 'float32'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    # read file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Replace data of the string type\n",
    "    df['HourlyPrecipitation'] = df['HourlyPrecipitation'].replace('T', 0.0)\n",
    "    # convert \"DATE\" to datetime type\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    # convert \"HourlyPrecipitation\" to numeric type\n",
    "    df['HourlyPrecipitation'] = pd.to_numeric(df['HourlyPrecipitation'], errors='coerce')\n",
    "    # convert value of 'na' into 0.0\n",
    "    df['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    #drop unnecessary colums\n",
    "    df.drop(df.columns.difference(['DATE',\n",
    "                                   'HourlyPrecipitation', \n",
    "                                   'HourlyWindSpeed']), 1, inplace=True)\n",
    "    # calculate hourly average as a daily values\n",
    "    df['DATE'] = df['DATE'].dt.date\n",
    "    df = df.groupby('DATE', as_index=False).agg({'HourlyWindSpeed': np.mean, 'HourlyPrecipitation': np.mean})\n",
    "    df['HourlyWindSpeed'] = df['HourlyWindSpeed'].map(lambda x: round(x, 2))\n",
    "    # remame columns\n",
    "    df.rename(columns={'HourlyWindSpeed': 'DailyAverageWindSpeed', 'HourlyPrecipitation': 'DailyPrecipitation'}, inplace=True)\n",
    "    df = df.astype({'DailyAverageWindSpeed':'float32', 'DailyPrecipitation':'float32', 'DATE' : 'datetime64[ns]'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data() -> pd.core.frame.DataFrame:\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2009_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2010_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2011_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2012_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2013_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2014_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2015_weather.csv\"\n",
    "        ]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n"
     ]
    }
   ],
   "source": [
    "hourly_data, daily_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>2015-12-31 18:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>2015-12-31 19:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>2015-12-31 22:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>2015-12-31 23:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73713 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009-01-01 00:51:00                  0.0             18.0\n",
       "1     2009-01-01 01:51:00                  0.0             18.0\n",
       "2     2009-01-01 02:51:00                  0.0             18.0\n",
       "3     2009-01-01 03:51:00                  0.0              8.0\n",
       "4     2009-01-01 04:51:00                  0.0             11.0\n",
       "...                   ...                  ...              ...\n",
       "11379 2015-12-31 18:51:00                  0.0              3.0\n",
       "11380 2015-12-31 19:51:00                  0.0              6.0\n",
       "11381 2015-12-31 20:51:00                  0.0             10.0\n",
       "11383 2015-12-31 22:51:00                  0.0              7.0\n",
       "11384 2015-12-31 23:51:00                  0.0              5.0\n",
       "\n",
       "[73713 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>6.93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.003542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.019375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.007436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATE  DailyAverageWindSpeed  DailyPrecipitation\n",
       "0   2009-01-01                  11.04            0.000000\n",
       "1   2009-01-02                   6.81            0.000000\n",
       "2   2009-01-03                   9.88            0.000000\n",
       "3   2009-01-04                   7.37            0.000000\n",
       "4   2009-01-05                   6.93            0.000000\n",
       "..         ...                    ...                 ...\n",
       "360 2015-12-27                   4.91            0.003542\n",
       "361 2015-12-28                   8.21            0.001154\n",
       "362 2015-12-29                   7.79            0.019375\n",
       "363 2015-12-30                   4.18            0.007436\n",
       "364 2015-12-31                   4.74            0.002286\n",
       "\n",
       "[2551 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sunset_sunrise_daily(csv_file: str) -> pd.core.frame.DataFrame:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df = df.astype({'Sunrise': 'int32', 'Sunset': 'int32', 'DATE':'datetime64[ns]' })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_sunrise_sunset_data() -> pd.core.frame.DataFrame:\n",
    "    sunrise_sunset_dataframes =[]\n",
    "    \n",
    "    weather_csv_files = [\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2009_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2010_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2011_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2012_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2013_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2014_weather.csv\",\n",
    "            r\"C:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\2015_weather.csv\"\n",
    "        ]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        sunrise_sunset_dataframe = clean_sunset_sunrise_daily(csv_file)\n",
    "        sunrise_sunset_dataframes.append(sunrise_sunset_dataframe)\n",
    "        \n",
    "    sunrise_sunset_data = pd.concat(sunrise_sunset_dataframes)\n",
    "    sunrise_sunset_data['DATE'] = pd.to_datetime(sunrise_sunset_data['DATE'])\n",
    "    sunrise_sunset_data = sunrise_sunset_data.astype({'Sunrise': 'int32', 'Sunset': 'int32'})\n",
    "    \n",
    "    return sunrise_sunset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2009-01-02 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2009-01-06 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2009-01-07 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2009-01-10 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2009-01-11 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>2015-12-27 23:59:00</td>\n",
       "      <td>719</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>2015-12-28 23:59:00</td>\n",
       "      <td>719</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>2015-12-29 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>2015-12-30 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>2015-12-31 23:59:00</td>\n",
       "      <td>720</td>\n",
       "      <td>1638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  Sunrise  Sunset\n",
       "55    2009-01-02 23:59:00      720    1640\n",
       "163   2009-01-06 23:59:00      720    1644\n",
       "202   2009-01-07 23:59:00      720    1645\n",
       "305   2009-01-10 23:59:00      720    1648\n",
       "343   2009-01-11 23:59:00      720    1649\n",
       "...                   ...      ...     ...\n",
       "11238 2015-12-27 23:59:00      719    1635\n",
       "11264 2015-12-28 23:59:00      719    1636\n",
       "11312 2015-12-29 23:59:00      720    1636\n",
       "11351 2015-12-30 23:59:00      720    1637\n",
       "11385 2015-12-31 23:59:00      720    1638\n",
       "\n",
       "[1826 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunrise_sunset_data = load_and_clean_sunrise_sunset_data()\n",
    "sunrise_sunset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_parquet_urls \u001b[39m=\u001b[39m find_taxi_parquet_urls()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m taxi_data \u001b[39m=\u001b[39m get_and_clean_taxi_data(all_parquet_urls)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m uber_data \u001b[39m=\u001b[39m load_and_clean_uber_data(UBER_CSV)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m hourly_weather_data, daily_weather_data \u001b[39m=\u001b[39m load_and_clean_weather_data()\n",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 24\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_taxi_dataframes \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m parquet_url \u001b[39min\u001b[39;00m parquet_urls:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     dataframe \u001b[39m=\u001b[39m get_and_clean_month_taxi_data(parquet_url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     add_distance_column(dataframe)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     all_taxi_dataframes\u001b[39m.\u001b[39mappend(dataframe)\n",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtpep_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     df\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtpep_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mtip_amount\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mtip_amount\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     df\u001b[39m=\u001b[39mconvert_id_to_coord(df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtrip_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     df\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrip_pickup_datetime\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mpickup_datetime\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mstart_lon\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpickup_longitude\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mstart_lat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpickup_latitude\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mend_lon\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mdropoff_longitude\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mend_lat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mdropoff_latitude\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mtip_amt\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mtip_amount\u001b[39m\u001b[39m'\u001b[39m})\n",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mdolocationid\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     DOlatitude\u001b[39m.\u001b[39mappend(shapefile[\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m][i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     DOlongitude\u001b[39m.\u001b[39mappend(shapefile[\u001b[39m'\u001b[39;49m\u001b[39mlongitude\u001b[39;49m\u001b[39m'\u001b[39;49m][i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpickup_longitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PUlongitude\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpickup_latitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PUlatitude\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py:1489\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, loc]\u001b[39m.\u001b[39msqueeze(axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1488\u001b[0m geo_col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_geometry_column_name\n\u001b[1;32m-> 1489\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39;49m(result\u001b[39m.\u001b[39;49mdtype, GeometryDtype):\n\u001b[0;32m   1490\u001b[0m     result\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m GeoSeries\n\u001b[0;32m   1491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, DataFrame):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_parquet_urls = find_taxi_parquet_urls()\n",
    "taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "uber_data = load_and_clean_uber_data(UBER_CSV)\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "sunrise_sunset_data = load_and_clean_sunrise_sunset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\1263730049.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2099839999.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:3: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\2252719857.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4001209316.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['DATE','Sunset','Sunrise']), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "uber_data = load_and_clean_uber_data(UBER_CSV)\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "sunrise_sunset_data = load_and_clean_sunrise_sunset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parquet_urls = find_taxi_parquet_urls()\n",
    "all_parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parquet_urls[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['latitude'] = shapefile['geometry'].centroid.y\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\4092193892.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile['longitude'] = shapefile['geometry'].centroid.x\n",
      "C:\\Users\\Silvia\\AppData\\Local\\Temp\\ipykernel_17652\\3217172957.py:23: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df.drop(df.columns.difference(['pickup_datetime',\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m taxi_data \u001b[39m=\u001b[39m get_and_clean_taxi_data(all_parquet_urls)\n",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_taxi_dataframes \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m parquet_url \u001b[39min\u001b[39;00m parquet_urls:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     dataframe \u001b[39m=\u001b[39m get_and_clean_month_taxi_data(parquet_url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     add_distance_column(dataframe)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     all_taxi_dataframes\u001b[39m.\u001b[39mappend(dataframe)\n",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 27\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_and_clean_month_taxi_data\u001b[39m(url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(url)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     df \u001b[39m=\u001b[39m df[:\u001b[39m10\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[0;32m    504\u001b[0m     path,\n\u001b[0;32m    505\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    508\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    509\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:244\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    242\u001b[0m     to_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39msplit_blocks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    245\u001b[0m     path,\n\u001b[0;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    252\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    253\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m     92\u001b[0m handles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m     94\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[0;32m     95\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m    103\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    105\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     path_or_handle \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    712\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 713\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    714\u001b[0m     path_or_buf,\n\u001b[0;32m    715\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    716\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    717\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    718\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    719\u001b[0m )\n\u001b[0;32m    721\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    722\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:368\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m             \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    367\u001b[0m             compression \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 368\u001b[0m         reader \u001b[39m=\u001b[39m BytesIO(req\u001b[39m.\u001b[39;49mread())\n\u001b[0;32m    369\u001b[0m     \u001b[39mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    370\u001b[0m         filepath_or_buffer\u001b[39m=\u001b[39mreader,\n\u001b[0;32m    371\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m         mode\u001b[39m=\u001b[39mfsspec_mode,\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    377\u001b[0m \u001b[39mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\http\\client.py:481\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m         s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safe_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlength)\n\u001b[0;32m    482\u001b[0m     \u001b[39mexcept\u001b[39;00m IncompleteRead:\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\http\\client.py:630\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[0;32m    624\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \n\u001b[0;32m    626\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[0;32m    632\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data(all_parquet_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:11:33</td>\n",
       "      <td>1.049745</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.961764</td>\n",
       "      <td>40.809457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 00:18:24</td>\n",
       "      <td>2.191297</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.961764</td>\n",
       "      <td>40.809457</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 00:26:19</td>\n",
       "      <td>3.895404</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.756688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 00:45:26</td>\n",
       "      <td>3.043737</td>\n",
       "      <td>2.37</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.756688</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 00:59:21</td>\n",
       "      <td>1.516475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>40.766948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-01 00:07:31</td>\n",
       "      <td>0.981286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.978632</td>\n",
       "      <td>40.783961</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-01 00:47:08</td>\n",
       "      <td>0.981286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.978632</td>\n",
       "      <td>40.783961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-01 00:58:04</td>\n",
       "      <td>4.013493</td>\n",
       "      <td>2.70</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.940772</td>\n",
       "      <td>40.818258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-01 00:29:25</td>\n",
       "      <td>1.986939</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.742279</td>\n",
       "      <td>-74.007486</td>\n",
       "      <td>40.726290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-01 00:39:02</td>\n",
       "      <td>6.058989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-74.007486</td>\n",
       "      <td>40.726290</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>40.766948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-01 00:06:53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>40.685634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-01 00:03:59</td>\n",
       "      <td>8.023809</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.973049</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.932831</td>\n",
       "      <td>40.857108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01 00:21:17</td>\n",
       "      <td>8.847351</td>\n",
       "      <td>5.80</td>\n",
       "      <td>-73.932831</td>\n",
       "      <td>40.857108</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01 00:37:53</td>\n",
       "      <td>14.105359</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.977982</td>\n",
       "      <td>40.653612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01 00:06:37</td>\n",
       "      <td>2.844034</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.804334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-01 00:24:06</td>\n",
       "      <td>1.784109</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.940772</td>\n",
       "      <td>40.818258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-02-01 00:33:59</td>\n",
       "      <td>1.587918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.951292</td>\n",
       "      <td>40.804334</td>\n",
       "      <td>-73.968168</td>\n",
       "      <td>40.797962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-02-01 00:44:27</td>\n",
       "      <td>5.362353</td>\n",
       "      <td>4.32</td>\n",
       "      <td>-73.968168</td>\n",
       "      <td>40.797962</td>\n",
       "      <td>-73.941399</td>\n",
       "      <td>40.841709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-02-01 00:01:50</td>\n",
       "      <td>0.990751</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>40.734576</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>40.742279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-02-01 00:25:46</td>\n",
       "      <td>1.351868</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.977569</td>\n",
       "      <td>40.764421</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.756729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime  trip_distance  tip_amount  pickup_longitude  \\\n",
       "0 2015-01-01 00:11:33       1.049745        1.40        -73.951292   \n",
       "1 2015-01-01 00:18:24       2.191297        0.00        -73.961764   \n",
       "2 2015-01-01 00:26:19       3.895404        2.90        -73.973049   \n",
       "3 2015-01-01 00:45:26       3.043737        2.37        -73.972356   \n",
       "4 2015-01-01 00:59:21       1.516475        0.00        -73.957012   \n",
       "5 2015-01-01 00:07:31       0.981286        0.00        -73.978632   \n",
       "6 2015-01-01 00:47:08       0.981286        0.00        -73.973049   \n",
       "7 2015-01-01 00:58:04       4.013493        2.70        -73.973049   \n",
       "8 2015-01-01 00:29:25       1.986939        0.00        -73.996971   \n",
       "9 2015-01-01 00:39:02       6.058989        0.00        -74.007486   \n",
       "0 2015-02-01 00:06:53       0.000000        0.00        -73.986114   \n",
       "1 2015-02-01 00:03:59       8.023809        0.00        -73.973049   \n",
       "2 2015-02-01 00:21:17       8.847351        5.80        -73.932831   \n",
       "3 2015-02-01 00:37:53      14.105359        5.00        -73.951010   \n",
       "4 2015-02-01 00:06:37       2.844034        0.00        -73.951010   \n",
       "5 2015-02-01 00:24:06       1.784109        0.00        -73.951292   \n",
       "6 2015-02-01 00:33:59       1.587918        0.00        -73.951292   \n",
       "7 2015-02-01 00:44:27       5.362353        4.32        -73.968168   \n",
       "8 2015-02-01 00:01:50       0.990751        0.95        -74.002875   \n",
       "9 2015-02-01 00:25:46       1.351868        0.00        -73.977569   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
       "0        40.804334         -73.961764         40.809457  \n",
       "1        40.809457         -73.973049         40.791705  \n",
       "2        40.791705         -73.972356         40.756688  \n",
       "3        40.756688         -73.951010         40.778766  \n",
       "4        40.780436         -73.959635         40.766948  \n",
       "5        40.783961         -73.973049         40.791705  \n",
       "6        40.791705         -73.978632         40.783961  \n",
       "7        40.791705         -73.940772         40.818258  \n",
       "8        40.742279         -74.007486         40.726290  \n",
       "9        40.726290         -73.959635         40.766948  \n",
       "0        40.685634         -73.986114         40.685634  \n",
       "1        40.791705         -73.932831         40.857108  \n",
       "2        40.857108         -73.951010         40.778766  \n",
       "3        40.778766         -73.977982         40.653612  \n",
       "4        40.778766         -73.951292         40.804334  \n",
       "5        40.804334         -73.940772         40.818258  \n",
       "6        40.804334         -73.968168         40.797962  \n",
       "7        40.797962         -73.941399         40.841709  \n",
       "8        40.734576         -73.996971         40.742279  \n",
       "9        40.764421         -73.965146         40.756729  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    weatherId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Date DATE,\n",
    "    HourlyPrecipitation FLOAT,\n",
    "    HourlyWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    weatherId INTEGER PRIMARY KEY AUTOINCREMENT\n",
    "    Date DATE,\n",
    "    DailyPrecipitation FLOAT,\n",
    "    DailyAverageWindSpeed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    taxi_tripId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_datetime DATE,\n",
    "    distance FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    uber_tripId INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_datetime DATE,\n",
    "    distance FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "SUNRISE_SUNSET_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sunrise_sunsets\n",
    "(\n",
    "    sunrise_sunsetID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Date DATE,\n",
    "    Sunrise INTEGER,\n",
    "    Sunset INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)\n",
    "    f.write(SUNRISE_SUNSET_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) near \"Date\": syntax error\n[SQL: \nCREATE TABLE IF NOT EXISTS daily_weather\n(\n    weatherId INTEGER PRIMARY KEY AUTOINCREMENT\n    Date DATE,\n    DailyPrecipitation FLOAT,\n    DailyAverageWindSpeed FLOAT\n);\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mOperationalError\u001b[0m: near \"Date\": syntax error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Silvia\\Documents\\GitHub\\4501FinalProject_Group14\\test.ipynb Cell 32\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# if the line is a semicolon, execute the query\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m line:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     connection\u001b[39m.\u001b[39;49mexecute(db\u001b[39m.\u001b[39;49mtext(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(query)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Silvia/Documents/GitHub/4501FinalProject_Group14/test.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     query \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1306\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[0;32m   1303\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[0;32m   1304\u001b[0m     )\n\u001b[0;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1306\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    330\u001b[0m ):\n\u001b[0;32m    331\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[1;32m--> 332\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[0;32m    333\u001b[0m             \u001b[39mself\u001b[39;49m, multiparams, params, execution_options\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[0;32m   1486\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1487\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1491\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[0;32m   1492\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1499\u001b[0m     dialect,\n\u001b[0;32m   1500\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[0;32m   1501\u001b[0m     compiled_sql,\n\u001b[0;32m   1502\u001b[0m     distilled_params,\n\u001b[0;32m   1503\u001b[0m     execution_options,\n\u001b[0;32m   1504\u001b[0m     compiled_sql,\n\u001b[0;32m   1505\u001b[0m     distilled_params,\n\u001b[0;32m   1506\u001b[0m     elem,\n\u001b[0;32m   1507\u001b[0m     extracted_params,\n\u001b[0;32m   1508\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1510\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[0;32m   1511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[0;32m   1512\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1513\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1517\u001b[0m         ret,\n\u001b[0;32m   1518\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[0;32m   1864\u001b[0m     )\n\u001b[0;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[0;32m   2042\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m-> 2043\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[0;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[0;32m   2045\u001b[0m     )\n\u001b[0;32m   2046\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2047\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[0;32m   1821\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) near \"Date\": syntax error\n[SQL: \nCREATE TABLE IF NOT EXISTS daily_weather\n(\n    weatherId INTEGER PRIMARY KEY AUTOINCREMENT\n    Date DATE,\n    DailyPrecipitation FLOAT,\n    DailyAverageWindSpeed FLOAT\n);\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    with open(DATABASE_SCHEMA_FILE, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        query = []\n",
    "        for line in lines:\n",
    "            query.append(line)\n",
    "            # if the line is a semicolon, execute the query\n",
    "            if \";\" in line:\n",
    "                connection.execute(db.text(\"\".join(query)))\n",
    "                query = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing taxi_trips\n",
      "writing uber_trips\n",
      "writing hourly_weather\n",
      "writing daily_weather\n",
      "writing sun_data\n"
     ]
    }
   ],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "    \"sun_data\": sunrise_sunset_data\n",
    "}\n",
    "\n",
    "for table, df in map_table_name_to_dataframe.items():\n",
    "    print(\"writing\", table)\n",
    "    df.to_sql(table, engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query: str, outfile: str):\n",
    "    '''Writes the query to the outfile.\n",
    "\n",
    "    Keyword arguments:\n",
    "    query -- The query to write.\n",
    "    outfile -- The name of the file to write to.\n",
    "    '''\n",
    "\n",
    "    with open(QUERY_DIRECTORY + outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"SELECT strftime('%H', pickup_datetime) AS time, COUNT(*) AS num\n",
    "FROM taxi_trips\n",
    "GROUP BY time\n",
    "ORDER BY num DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00', 20)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, \"most_popular_hour.sql\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
